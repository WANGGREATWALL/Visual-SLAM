# 第2讲 初识SLAM

`王琛` | `2020/10/02`

[toc]

> **主要目标:** 本讲概括地介绍一个视觉 SLAM 系统的结构, 作为后续内容的大纲. 实践部分介绍环境搭建、程序基本知识, 最后完成一个 "Hello SLAM" 程序.
>
> 1. 理解一个视觉 SLAM 框架由哪几个模块组成, 各模块的任务是什么?
> 2. 搭建编程环境, 为开发和实验做准备;
> 3. 理解如何在 Linux 下编译并运行一个程序, 如果程序出了问题, 又该如何对它进行调试;
> 4. 掌握 cmake 的基本使用方法;

## 2.1 经典视觉SLAM框架

SLAM 需要一个完善的算法框架, 而经过研究者们长期的努力工作, 现有这个框架已经定型了.

![image-20201002173359361](https://i.loli.net/2020/10/03/7uov1EpH4TRChZ9.png)

视觉 SLAM 流程包括以下步骤:

1. 传感器信息读取. 在视觉 SLAM 中主要为相机图像信息的读取和预处理. 如果是在机器人中, 还可能有码盘、惯性传感器等信息的读取和同步;
2. **视觉里程计** (Visual Odometry, VO). 视觉里程计的任务是估算相邻图像间相机的运动, 以及局部地图的样子. VO 又称为前端 (Front End);
3. **后端优化** (Optimization). 后端接受不同时刻视觉里程计测量的相机位姿, 以及回环检测的信息, 对它们进行优化, 得到全局一致的轨迹和地图. 由于接在 VO 之后, 又称为后端 (Back End);
4. **回环检测** (Loop Closing). 回环检测判断机器人是否到达过先前的位置. 如果检测到回环, 它会把信息提供给后端进行处理;
5. **建图** (Mapping). 它根据估计的轨迹, 建立与任务要求对应的地图;

经典的视觉 SLAM 框架是过去十几年的研究成果. 这个框架本身及其所包含的算法已经基本定型, 并且已经在许多视觉程序库和机器人程序库中提供. 依靠这些算法, 我们能够构建一个视觉 SLAM 系统, 使之在正常的工作环境里实时定位与建图. 因此, 我们说, **如果把工作环境限定在静态、刚体、光照变化不明显、没有人为干扰的场景**, 那么这个 SLAM 系统是相当成熟的了.

### 2.1.1 视觉里程计

